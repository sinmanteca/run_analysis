Code Book
=========

The [*Human Activity Recognition Using Smartphones Data Set*](http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones) is freely available from the Machine Learning Repository. For this project, the raw data were downloaded from a [mirror location](https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip). These data were originally published in 2012.

---------

### Experimental design and background

Volunteers between the ages of 19 and 64 years performed six activities while wearing a smartphone on their waist. Using the device's accelerometer and gyroscope, the triaxial linear acceleration and angular velocity were captured at a constant rate of 50Hz. 

The data set was randomly partitioned into two sets. The training data were generated by 70% of the volunteers and the test data were generated by the remainder. Sensor signals were pre-processed with noise filters.

### Raw data

The raw data are divided into several files which include:

- activity_labels.txt - activity ID, activity label (integer, string)
- features.txt - feature ID, feature label (integer, string)
- test/subject_test.txt - subject IDs each test observation (integer)
- test/y_test.txt - activity IDs for each test observation  (integer)
- test/X_test.txt - measurements for each feature in each test observation (numeric)
- train/subject_train.txt - subject IDs each training observation (integer)
- train/y_train.txt - activity IDs for each training observation (integer)
- train/X_train.txt - measurements for each feature in each training observation (numeric)

There are 561 features describing the mean, standard deviation, and other descriptive statistics that have been calculated from inertial signals data from the smartphone's accelerometer and gyroscope. As these data have been normalized and bounded within [-1,1], all features are unit-less. The inertial signals data (not used in the tidy data set) are provided in standard gravitational units 'g' for signals measuring linear acceleration and radians/second for signals measuring angular velocity. A detailed explanation of the each feature and the inertial signals can be found in the README.txt and features_info.txt files which accompany the data.


### Processing summary
The subject and activity ID tables were appended to the test and training measurement tables. The resulting test and training data sets were then merged into a single data set. All columns were labelled, edited to be more human-readable, and converted to lowercase.

In the merged data set, activity IDs for each observation were replaced with the corresponding activity label. A subset of measurements that captured the mean and standard deviation was selected (features labelled with *mean()* and *std()*). The average of these measurements was calculated for each subject and activity grouping. 

This wide form tidy data set was then transformed into long form tidy data set using the following fields (first 10 observations shown below):

``` 
Source: local data frame [11,880 x 4]

   subject           activity                        feature     value
     (int)              (chr)                         (fctr)     (dbl)
1        1             LAYING body-accelerometer-mean-x-axis 0.2215982
2        1            SITTING body-accelerometer-mean-x-axis 0.2612376
3        1           STANDING body-accelerometer-mean-x-axis 0.2789176
4        1            WALKING body-accelerometer-mean-x-axis 0.2773308
5        1 WALKING_DOWNSTAIRS body-accelerometer-mean-x-axis 0.2891883
6        1   WALKING_UPSTAIRS body-accelerometer-mean-x-axis 0.2554617
7        2             LAYING body-accelerometer-mean-x-axis 0.2813734
8        2            SITTING body-accelerometer-mean-x-axis 0.2770874
9        2           STANDING body-accelerometer-mean-x-axis 0.2779115
10       2            WALKING body-accelerometer-mean-x-axis 0.2764266
..     ...                ...                            ...       ...
```


-------
Source:

Davide Anguita, Alessandro Ghio, Luca Oneto, Xavier Parra and Jorge L. Reyes-Ortiz. A Public Domain Dataset for Human Activity Recognition Using Smartphones. 21th European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning, ESANN 2013. Bruges, Belgium 24-26 April 2013.